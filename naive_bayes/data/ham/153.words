Changing
the
loadaverage
threshold
wont
do
anything
here
The
bproc
mods
to
the
batch
queue
system
use
a
slot
allocation
rather
than
loadavg
The
slot
allocator
assumes
that
the
best
allocation
is
1
job
per
CPU
on
a
compute
node
That
is
done
for
three
reasons
First
thats
generally
a
better
allocation
for
any
scientific
computation
while
loadavg
is
better
suited
for
general
purpose
servers
Second
loadavg
is
more
expensive
to
compute
in
that
it
will
generate
extra
net
traffic
and
disrupt
the
cache
and
take
extra
locks
on
the
compute
nodes
which
will
hurt
performance
Compute
jobs
often
have
bursts
of
IO
where
the
job
will
sleep
waiting
followed
by
long
periods
of
pure
computation
That
can
cause
a
brief
dip
in
apparent
loadavg
and
lead
to
bad
allocations
Gday
sjames
Quoting
gilfoyle
ggilfoylmindspringcom
Hi
Steven
Happy
New
Year
and
yet
another
question
about
the
Richmond
cluster
I
have
been
experimenting
with
different
ways
of
running
the
cluster
and
I
have
run
into
a
problem
with
the
batch
system
Im
submitting
jobs
in
two
different
ways
one
uses
the
beomap
command
to
allocate
slave
nodes
and
the
other
just
picks
the
slave
nodes
by
hand
Im
using
this
second
method
because
the
limiting
factor
now
is
the
ability
to
transfer
the
data
files
to
the
slave
nodes
I
was
thinking
that
I
could
transfer
the
data
on
the
first
pass
and
leave
it
there
for
later
passes
to
speed
things
up
The
problem
now
is
that
after
many
jobs
are
submitted
from
60100
of
so
the
remaining
jobs
get
sent
to
the
b
batch
queue
and
never
run
This
has
happened
even
when
the
varspool
area
is
not
full
My
thoughts
are
the
following
1
Can
we
reset
the
average
cpu
load
with
the
atd
l
command
Ive
tried
this
and
it
seems
to
have
little
effect
2
Can
we
restart
the
jobs
in
the
queue
Now
they
just
sit
there
and
never
get
started
3
In
some
of
the
recent
analysis
runs
the
varspoolmqueue
area
has
filled
up
and
hung
things
up
Before
it
was
the
varspoolat
or
varspoolmail
areas
Do
you
have
any
idea
what
would
cause
that
Should
we
make
a
link
for
varspoolmqueue
to
one
of
RAID
disks
so
there
is
plenty
of
space
Let
me
know
what
you
think
Thanksinadvance
jerry
Dr
Gerard
P
Gilfoyle
Physics
Department
email
ggilfoylrichmondedu
University
of
Richmond
VA
23173
phone
8042898255
USA
fax
8042898482
steven
james
director
of
research
linux
labs
LinuxBIOS
Cluster
Solutions
230
peachtree
st
nw
ste
2705
HighSpeed
Colocation
Hosting
atlantagaus
30303
Linux
Hardware
Development
Support
httpwwwlinuxlabscom
Visit
us
at
SuperComputing
2002
Booth
1441
officefax
40457777473
